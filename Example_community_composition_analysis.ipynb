{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Example_community_composition_analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/cadurkin/Phytoplankton_Taxomony_Course/blob/master/Example_community_composition_analysis.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "nQweLZAiXurQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Example analysis of phytoplankton community composition\n",
        "\n",
        "- First import your data.  \n",
        "- Data should be saved as a .csv file (comma-separated values).\n",
        "- import libraries needed to analyze the data.  Pandas helps to work with data matrices.  Numpy works with data arrays. Matplotlib is used for plotting."
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "4H3YJksdXurU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install scikit-bio\n",
        "!git clone https://github.com/cadurkin/Phytoplankton_Taxomony_Course.git  # Download data\n",
        "  \n",
        "import skbio as skbio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "data = pd.read_csv('Phytoplankton_Taxomony_Course/Example_Station_M_cellcounts.csv',infer_datetime_format=True,index_col=0)\n",
        "#display the first 10 rows to make sure it looks ok\n",
        "data.iloc[0:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OT4IEAOCXurj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<b> Organize data so that cell counts are in separate matrices from metadata"
      ]
    },
    {
      "metadata": {
        "id": "zcSXounXXurm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#separate metadata rows and columns from the raw cell counts\n",
        "cell_counts_andType = data.loc[data.Parameter != 'metadata']\n",
        "cell_counts = cell_counts_andType.drop('Parameter',axis=1)\n",
        "#display the top part of the cell count matrix to make sure it looks correct\n",
        "cell_counts.iloc[0:10]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lez4OpHkXury",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Create matrix with all the metadata\n",
        "metadata_andType = data.loc[data.Parameter == 'metadata']\n",
        "metadata = metadata_andType.drop('Parameter',axis=1)\n",
        "metadata"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nHgoK9GrXur6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Calculate the cell concentrations\n",
        "- Divide cell counts by the number of sedwick rafter squares counted to calculate cells per uL.  One square = 1 microliter of sample.\n",
        "- Multiply the cells per uL by the dilution or concentration factor, whichever is appropriate.  In this dataset, highly concentrated samples were diluted.  If you settled cells into a smaller volume, you will need to use the dilution factor.  For example, 1 mL concentrated from 10 mL = 0.1 dilution factor.\n"
      ]
    },
    {
      "metadata": {
        "id": "guGZ62JOXur9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cells_per_uL = cell_counts.divide(metadata.loc['squares_counted'], axis = 1)\n",
        "cells_per_uL_dilutionCorrected = cells_per_uL.multiply(metadata.loc['Dilution_factor'], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "naG5Chg7XusE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#convert the cell concentration to cells per mL\n",
        "cells_per_mL = cells_per_uL_dilutionCorrected.multiply(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3PTXOvVyXusM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Calculate Bray-Curtis dissimilarity index matrix\n",
        "- using scipy library of functions\n",
        "- \"pdist\" calculates the pairwise distance between all samples using a chosen metric.  Here, we are using the Bray-Curtis similary metric.\n",
        "- the pdist function requires an array with samples as the columns and species as the rows.  So, we need to transform our species abundance matrix using the pandas function \".T\".  \n",
        "- For the \"pdist\" function to work, the species abundance matrix also needs to be converted to an \"array\", which does not have any labels in the rows or columns.\n",
        "- later we will need our similarity matrix to be in a \"square\" form, instead of the condensed output that pdist provides by default.  The squareform function converts the condensed matrix into a square.\n",
        "- The functions used in later steps will also require the similarity matrix to be in a specialized \"distance matrix\" format used by that function.  The last line of code here converts our square matrix into a distance matrix that includes the sample IDs."
      ]
    },
    {
      "metadata": {
        "id": "W7VeLXQbXusQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import pdist\n",
        "from scipy.spatial.distance import squareform\n",
        "\n",
        "bc_matrix_condensed = pdist(np.asarray(cells_per_mL.T),metric = 'braycurtis')\n",
        "bc_matrix_square = squareform(bc_matrix_condensed)\n",
        "\n",
        "sample_list = np.asarray(cell_counts.T.index)\n",
        "bc_matrix = skbio.stats.distance.DistanceMatrix(data = bc_matrix_square,ids=sample_list)\n",
        "bc_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZKBnEc7VXusa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Perform principal coordinates analysis (aka: multi-dimensional scaling analysis) with bray-curtis matrix\n",
        "\n",
        "- PCoA attempts to place the distances from the matrix into dimensional space.\n",
        "- Visualizing distances in space helps identify which groups of samples are most similar."
      ]
    },
    {
      "metadata": {
        "id": "iK2rWXPtXusd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from skbio.stats import ordination\n",
        "#use the special distance matrix format as the input matrix for the pcoa function (bc_matrix)\n",
        "MDS = ordination.pcoa(bc_matrix)\n",
        "\n",
        "#Plot a figure visualizing 2-D distance between samples using the first two ordinatation axes\n",
        "\n",
        "%matplotlib inline\n",
        "plt.plot(MDS.samples['PC1'],MDS.samples['PC2'], lw=0, marker = 'o')\n",
        "\n",
        "#Add labels to the graph so you know which samples are clustering\n",
        "for x in np.arange(0,len(MDS.samples['PC1'])):\n",
        "    plt.text(MDS.samples.PC1[x],MDS.samples.PC2[x],sample_list[x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "11TMpQcHXusp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Identify clusters of samples and test whether they are significantly different\n",
        "- here we are using k-means clustering.  You could also use the clustering method explained further down\n",
        "- k-means clustering requires an apriori defined number of clusters to identify\n",
        "- output of k-means clustering is a list of the corresponding group that each sample belongs to."
      ]
    },
    {
      "metadata": {
        "id": "zEZi-wTVXusr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "#This function requires the square-shaped bray-curtis similarity array, without specialized formating\n",
        "kmeans = KMeans(n_clusters=3, random_state=0).fit(bc_matrix_square)\n",
        "kmeans.labels_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eqXTU6ubXus1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#test whether differences among groups are significant.\n",
        "permanova_test = skbio.stats.distance.permanova(bc_matrix,kmeans.labels_)\n",
        "permanova_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FqakHzJlXus_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "from pandas import DataFrame\n",
        "## Explore which species might be driving significant differences among groups of samples\n",
        "- Here we use a \"simper\" analysis to idenify which species contribute the most to the the percent dissimilarity between two groups of samples\n",
        "- We are using the simper analysis function in the ecopy library of functions\n",
        "- We are using the k-means clustering results to define groups of samples\n",
        "- Here, we print out the top ten species contributing to differences among groups\n",
        "- Simper is not an especially robust statistical analysis, but helps point you toward the species driving differences among groups found through more robust approaches (like PERMANOVA)"
      ]
    },
    {
      "metadata": {
        "id": "hSx-gu9B94Ci",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##Here we define the simper function.  Copied from ecopy module, but edited to be compatible with pandas updates\n",
        "\n",
        "from pandas import DataFrame\n",
        "\n",
        "def simper(data, factor, spNames=None):\n",
        "\tif not isinstance(data, (DataFrame, np.ndarray)):\n",
        "\t\tmsg = 'datamust be either numpy array or dataframe'\n",
        "\t\traise ValueError(msg)\n",
        "\tif isinstance(data, DataFrame):\n",
        "\t\tif (data.dtypes == 'object').any():\n",
        "\t\t\tmsg = 'DataFrame can only contain numeric values'\n",
        "\t\t\traise ValueError(msg)\n",
        "\t\tX = np.array(data).astype('float')\n",
        "\t\tspNames = data.columns\n",
        "\telse:\n",
        "\t\tX = data.astype('float')\n",
        "\tif np.min(np.sum(X, axis=1))==0:\n",
        "\t\tmsg = 'One row is entirely zeros, distance calculations will be meaningless'\n",
        "\t\traise ValueError(msg)\n",
        "\tif (X < 0).any():\n",
        "\t\tmsg = 'Matrix contains negative values'\n",
        "\t\traise ValueError(msg)\n",
        "\tif spNames is None:\n",
        "\t\tspNames = np.arange(X.shape[1])\n",
        "\ts1 = np.array(spNames)\n",
        "\tg1 = np.array(factor)\n",
        "\tif len(g1) != X.shape[0]:\n",
        "\t\tmsg = 'Factor length must equal number of rows in matrix'\n",
        "\t\traise ValueError(msg)\n",
        "\tif len(s1) != X.shape[1]:\n",
        "\t\tmsg = 'Species names must equal number of columns in matrix'\n",
        "\t\traise ValueError(msg)\n",
        "\tgroupIDs = np.unique(g1)\n",
        "\tprint('\\nComparison indices:')\n",
        "\ti = 0\n",
        "\twhile i < len(groupIDs)-1:\n",
        "\t\tt1 = X[g1==groupIDs[i],:]\n",
        "\t\tj = i+1\n",
        "\t\twhile j < len(groupIDs):\n",
        "\t\t\tt2 = X[g1==groupIDs[j],:]\n",
        "\t\t\tcomp = '{0}-{1}'.format(groupIDs[i], groupIDs[j])\n",
        "\t\t\tn1 = t1.shape[0]\n",
        "\t\t\tn2 = t2.shape[0]\n",
        "\t\t\tdeltaI = np.zeros((n1*n2, t1.shape[1]))\n",
        "\t\t\tk = 0\n",
        "\t\t\twhile k < n1*n2:\n",
        "\t\t\t\tfor idx1 in range(n1):\n",
        "\t\t\t\t\tfor idx2 in range(n2):\n",
        "\t\t\t\t\t\tdeltaI[k,:] = brayWrap(t1[idx1,:], t2[idx2,:])\n",
        "\t\t\t\t\t\tk += 1\n",
        "\t\t\tspMeans =np.round(deltaI.mean(axis=0), 2)\n",
        "\t\t\tspSds = np.round(deltaI.std(axis=0, ddof=1), 2)\n",
        "\t\t\tspRat = np.round(spMeans/spSds, 2)\n",
        "\t\t\tspPct = np.round(spMeans/spMeans.sum()*100, 2)\n",
        "\t\t\ttempDF = DataFrame({'sp_mean': spMeans,\n",
        "\t\t\t\t\t\t'sp_sd': spSds,\n",
        "\t\t\t\t\t\t'ratio': spRat,\n",
        "\t\t\t\t\t\t'sp_pct': spPct}, \n",
        "\t\t\t\t\t\tindex=[[comp]*len(spNames), spNames])\n",
        "\t\t\ttempDF.sort_values(by=['sp_pct'], axis=0, ascending=False, inplace=True)\n",
        "\t\t\ttempDF['cumulative'] = np.cumsum(tempDF['sp_pct'])\n",
        "\t\t\ttempDF = tempDF[['sp_mean', 'sp_sd', 'ratio', 'sp_pct', 'cumulative']]\n",
        "\t\t\tif i==0 and j==i+1:\n",
        "\t\t\t\tfinalDF = tempDF\n",
        "\t\t\telse:\n",
        "\t\t\t\tfinalDF = finalDF.append(tempDF)\n",
        "\t\t\tprint(comp)\n",
        "\t\t\tj += 1\n",
        "\t\ti += 1\n",
        "\treturn finalDF\n",
        "\n",
        "\n",
        "\n",
        "def brayWrap(x,y):\n",
        "\ttemp = np.array([x, y])\n",
        "\tsums = np.sum(temp)\n",
        "\tdeltas = np.apply_along_axis(brayFunc, 0, temp, sums=sums)\n",
        "\treturn deltas\n",
        "\n",
        "def brayFunc(m, sums):\n",
        "\tdelta = np.abs(m[0]-m[1])/sums\n",
        "\treturn 100*delta\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "02zuTuAP-_hE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Now run the simper analysis\n"
      ]
    },
    {
      "metadata": {
        "id": "EGWnZmpjXutD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "species_driving_differences = simper(cells_per_mL.T,kmeans.labels_)\n",
        "print(species_driving_differences.loc['0-1'][1:10])\n",
        "print(species_driving_differences.loc['0-2'][1:10])\n",
        "print(species_driving_differences.loc['1-2'][1:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ie0Ba8mACFnA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Explore how these species abundances differ among the three groups\n",
        "\n",
        "- boxplots allow you to look at the distribution of sample values within groups\n",
        "- can then use an ANOVA to test of signifiant differences in abundance of specific organisms among these groups"
      ]
    },
    {
      "metadata": {
        "id": "6SEkdzRv_Jgp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "group0_samples = cell_counts.T.iloc[kmeans.labels_ == 0]\n",
        "group1_samples = cell_counts.T.iloc[kmeans.labels_ == 1]\n",
        "group2_samples = cell_counts.T.iloc[kmeans.labels_ == 2]\n",
        "\n",
        "plt.subplots(figsize=(10,8))\n",
        "plt.subplot(3,3,1)\n",
        "plt.boxplot([group0_samples['Chaetoceros_concavicornus'],group1_samples['Chaetoceros_concavicornus'],group2_samples['Chaetoceros_concavicornus']],positions=[1,2,3],widths = .75,labels = ['0','1','2'])\n",
        "plt.title('Chaetoceros_concavicornus')\n",
        "plt.subplot(3,3,2)\n",
        "plt.boxplot([group0_samples['Dinoflagellate_medium'],group1_samples['Dinoflagellate_medium'],group2_samples['Dinoflagellate_medium']],positions=[1,2,3],widths = .75,labels = ['0','1','2'])\n",
        "plt.title('Dinoflagellate_medium')\n",
        "plt.subplot(3,3,3)\n",
        "plt.boxplot([group0_samples['Dinoflagellate_small'],group1_samples['Dinoflagellate_small'],group2_samples['Dinoflagellate_small']],positions=[1,2,3],widths = .75,labels = ['0','1','2'])\n",
        "plt.title('Dinoflagellate_small')\n",
        "plt.subplot(3,3,4)\n",
        "plt.boxplot([group0_samples['Centric_small'],group1_samples['Centric_small'],group2_samples['Centric_small']],positions=[1,2,3],widths = .75,labels = ['0','1','2'])\n",
        "plt.title('Centric_small')\n",
        "plt.subplot(3,3,5)\n",
        "plt.boxplot([group0_samples['Centric_medium'],group1_samples['Centric_medium'],group2_samples['Centric_medium']],positions=[1,2,3],widths = .75,labels = ['0','1','2'])\n",
        "plt.title('Centric_medium')\n",
        "plt.subplot(3,3,6)\n",
        "plt.boxplot([group0_samples['Skeletonema'],group1_samples['Skeletonema'],group2_samples['Skeletonema']],positions=[1,2,3],widths = .75,labels = ['0','1','2'])\n",
        "plt.title('Skeletonema')\n",
        "plt.subplot(3,3,7)\n",
        "plt.boxplot([group0_samples['Emeliania'],group1_samples['Emeliania'],group2_samples['Emeliania']],positions=[1,2,3],widths = .75,labels = ['0','1','2'])\n",
        "plt.title('Emeliania')\n",
        "plt.subplot(3,3,8)\n",
        "plt.boxplot([group0_samples['Pseudo-nitzschia_large'],group1_samples['Pseudo-nitzschia_large'],group2_samples['Pseudo-nitzschia_large']],positions=[1,2,3],widths = .75,labels = ['0','1','2'])\n",
        "plt.title('Pseudo-nitzschia_large')\n",
        "plt.subplot(3,3,9)\n",
        "plt.boxplot([group0_samples['Fragilariopsis_small_rounded'],group1_samples['Fragilariopsis_small_rounded'],group2_samples['Fragilariopsis_small_rounded']],positions=[1,2,3],widths = .75,labels = ['0','1','2'])\n",
        "plt.title('Fragilariopsis_small')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oCAk3LgXXutL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Alternative clustering approaches\n",
        "- heierarchical clustering and visualization using a dendrogram"
      ]
    },
    {
      "metadata": {
        "id": "MMYCUIm-XutO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "\n",
        "#this function requires the condensed format of our bray-curtis similarity index\n",
        "linkage_matrix = linkage(bc_matrix_condensed, \"centroid\")\n",
        "plt.figure(figsize=[15,5])\n",
        "dendrogram(linkage_matrix, labels=sample_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YwfYF7ifXuto",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}